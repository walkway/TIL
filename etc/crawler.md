# crawler

- '크롤러'('로봇' 또는 '스파이더'라고도 함)는 한 웹페이지에서 다른 웹페이지로 연결되는 링크를 따라가며 웹사이트를 자동으로 검색하는 데 사용되는 프로그램을 가리키는 일반적인 용어
- 웹페이지가 무엇에 대한 것인지 파악하여 필요할 때 정보를 추출할 수 있도록 하는 것
- 웹페이지 재방문: 웹 콘텐츠는 지속적으로 변경되거나 삭제되고 새로운 위치로 이동함. 웹 크롤러는 정기적으로 페이지를 다시 방문하여 최신 버전의 콘텐츠를 색인화해야 함.
- Robots.txt 
  - Robots.txt를 통해 접근범위가 어디까지 가능한지 확인 필요
  - Robots.txt 프로토콜(로봇 제외 프로토콜이라고도 함)을 기반으로 크롤링할 페이지를 결정. 
  - 웹 페이지를 크롤링하기 전에, 웹 크롤러는 해당 페이지의 웹 서버에서 호스팅하는 Robots.txt 파일을 확인.
  - Robots.txt 파일은 호스팅된 웹사이트 또는 애플리케이션에 액세스하는 모든 봇에 대한 규칙을 지정하는 텍스트 파일
- 정적 크롤링
  - 한 페이지 내에서 원하는 정보가 전부 드러나는 정적인 데이터를 크롤링하여 가져오는 것
- 동적크롤링
  - 여러 페이지를 이동하며 마우스로 클릭하거나 타이핑을 통한 입력으로 확인할 수 있는 데이터를 가져오는 것
- beautifulsoup, selenium

https://modulabs.co.kr/blog/crawling-tips/
